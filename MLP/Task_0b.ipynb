{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6-final"
    },
    "colab": {
      "name": "Task_0b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZQHmrR0fzq7",
        "outputId": "cf6cf556-b054-4069-fb6e-547255607a1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!tar xf drive/MyDrive/Colab\\ Notebooks/data/mnist-png-format.tar.xz -C /content/"
      ],
      "id": "pZQHmrR0fzq7",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcgsHeQlWFGy"
      },
      "source": [
        "Enable CUDA for GPU acceleration \n"
      ],
      "id": "DcgsHeQlWFGy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUnCDlEmWCXq",
        "outputId": "f9dc735a-c766-400c-d402-166fd925ab38"
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "id": "lUnCDlEmWCXq",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbFdbVEHRAdI"
      },
      "source": [
        "Import data in PNG form and split into Train, Test, Validate and load\n"
      ],
      "id": "RbFdbVEHRAdI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "402833b7"
      },
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose, Grayscale\n",
        "\n",
        "train_set = '/content/mnist-png-format/train'\n",
        "test_set = '/content/mnist-png-format/test'\n",
        " \n",
        "batch_size = 256\n",
        "workers = 2\n",
        "\n",
        "transforms = Compose([\n",
        "                        Grayscale(num_output_channels=1),   # PNG file is RGB 3 layer convert to greyscal 1 layer\n",
        "                        ToTensor(),           \n",
        "                        Normalize(mean=(0.5), std=(0.5)), \n",
        "                        ])\n",
        "\n",
        "train_dataset = ImageFolder(train_set, transform=transforms)\n",
        "test_dataset = ImageFolder(test_set, transform=transforms)\n",
        "\n",
        "# Split Train dataset set into two (Train=85/Validation=15% split)\n",
        "train_size = int(len(train_dataset) * 0.85) \n",
        "validation_size = (len(train_dataset) - train_size) \n",
        "train, validation = random_split(train_dataset, [train_size, validation_size])\n",
        "\n",
        "# load data into usable format, mix/shuffle data so data is not in order \n",
        "train_data = DataLoader(train, batch_size = batch_size, shuffle = True, num_workers = workers, pin_memory=True)\n",
        "val_data  = DataLoader(validation, batch_size = batch_size, shuffle = True, num_workers = workers, pin_memory=True)\n",
        "test_data  = DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers = workers, pin_memory=True)"
      ],
      "id": "402833b7",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef3940db"
      },
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "class SingleLayerModel(nn.Module):\n",
        "    def __init__(self, neurons):\n",
        "        super().__init__()\n",
        "        self.hidden_1 = nn.Linear(28*28, neurons) # 28x28 Input image, number of neurons\n",
        "        self.output = nn.Linear(neurons, 10) # 10 class output 0-9\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1) \n",
        "        x = nn.functional.relu(self.hidden_1(x))\n",
        "        y = self.output(x)\n",
        "        return y"
      ],
      "id": "ef3940db",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzo3_Rs5RAdl"
      },
      "source": [
        "# Optimisable parameters\n",
        "learning_rate = [0.0001, 0.001, 0.01]\n",
        "train_epochs = 10\n",
        "neurons = [10, 30, 50, 100]\n",
        "\n",
        "ModelMLP  = SingleLayerModel(neurons[3])\n",
        "optimiser = optim.Adam(ModelMLP.parameters(), lr=learning_rate[1])\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "id": "Kzo3_Rs5RAdl",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJhgbrY3RAdn"
      },
      "source": [
        "def evaluate_model(model, eval_dataset):\n",
        "    model = model.to(device)\n",
        "    model.eval() # Set model mode to evaluation not training\n",
        "    correct_batch = 0\n",
        "    loss_batch = 0\n",
        "    with torch.no_grad():                 # Gradient graph not require for evaluation should reduce memory usage\n",
        "      for (imgs, labels) in eval_dataset: # loop through each batch\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        pred_y = model(imgs)\n",
        "        loss = loss_func(pred_y, labels)\n",
        "\n",
        "        pred = torch.max(pred_y, 1)[1]\n",
        "        correct_batch += (pred == labels).sum().item() # Calculate correct prediction where prediction == label \n",
        "        loss_batch += loss.item()\n",
        "\n",
        "    return correct_batch / len(eval_dataset.dataset), loss_batch / len(eval_dataset.dataset)"
      ],
      "id": "OJhgbrY3RAdn",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhtEgZzCRAdp",
        "outputId": "c765f095-75d0-4c67-c9f8-b4830ce5c79b"
      },
      "source": [
        "  ModelMLP = ModelMLP.to(device)\n",
        "  \n",
        "  for i in range(train_epochs): # training epochs\n",
        "    correct_batch = 0\n",
        "    loss_batch = 0\n",
        "\n",
        "    for (imgs, labels) in train_data: # loop through each batch \n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "      ModelMLP.train()\n",
        "      pred_y = ModelMLP(imgs)\n",
        "      loss = loss_func(pred_y, labels)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      pred = torch.max(pred_y, 1)[1]\n",
        "      correct_batch += (pred == labels).sum().item() # Calculate correct prediction where prediction == label \n",
        "      loss_batch += loss.item()\n",
        "\n",
        "    val_acc, val_loss = evaluate_model(ModelMLP, val_data)\n",
        "\n",
        "    print('Train accuracy = {0:.2%}, Train loss = {1:.6f} | \\\n",
        "           Validation accuracy = {2:.2%}, Validation loss = {3:.6f}'.format(correct_batch / len(train_data.dataset), loss_batch / len(train_data.dataset), val_acc, val_loss ))\n"
      ],
      "id": "EhtEgZzCRAdp",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy = 97.33%, Train loss = 0.000095 |          Validation accuracy = 97.38%, Validation loss = 0.000095\n",
            "Train accuracy = 97.52%, Train loss = 0.000089 |          Validation accuracy = 97.19%, Validation loss = 0.000098\n",
            "Train accuracy = 97.57%, Train loss = 0.000087 |          Validation accuracy = 97.29%, Validation loss = 0.000094\n",
            "Train accuracy = 97.61%, Train loss = 0.000085 |          Validation accuracy = 97.36%, Validation loss = 0.000096\n",
            "Train accuracy = 97.73%, Train loss = 0.000082 |          Validation accuracy = 97.47%, Validation loss = 0.000094\n",
            "Train accuracy = 97.83%, Train loss = 0.000079 |          Validation accuracy = 97.54%, Validation loss = 0.000092\n",
            "Train accuracy = 97.82%, Train loss = 0.000077 |          Validation accuracy = 97.52%, Validation loss = 0.000091\n",
            "Train accuracy = 97.91%, Train loss = 0.000076 |          Validation accuracy = 97.43%, Validation loss = 0.000093\n",
            "Train accuracy = 97.87%, Train loss = 0.000075 |          Validation accuracy = 97.44%, Validation loss = 0.000090\n",
            "Train accuracy = 97.96%, Train loss = 0.000073 |          Validation accuracy = 97.44%, Validation loss = 0.000092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU8jvlroRAds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03a9aa0-3f50-4ebc-9e7d-65e6df7adfbf"
      },
      "source": [
        "test, _ = evaluate_model(ModelMLP, test_data)\n",
        "print('Test accuracy = {0:.2%}'.format(test))"
      ],
      "id": "GU8jvlroRAds",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy = 96.88%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}